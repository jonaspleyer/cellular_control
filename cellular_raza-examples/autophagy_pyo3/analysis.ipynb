{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Autophagy Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific imports for cellular_raza\n",
    "# The package is named cr_autophagy\n",
    "# We want to reload the package when some of the behind-the scenes python functions change\n",
    "# This is what the importlib statements are for\n",
    "import importlib\n",
    "import cr_autophagy as cra\n",
    "importlib.reload(cra)\n",
    "\n",
    "# Imports of general-purpose python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pyvista as pv\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "output_path = cra.get_last_output_path()\n",
    "# output_path = Path(\"out/autophagy/2023-11-24-18:05:41\")\n",
    "print(output_path)\n",
    "simulation_settings = cra.get_simulation_settings(output_path)\n",
    "iter_0_particles = cra.get_particles_at_iter(output_path, 0)\n",
    "for col in iter_0_particles.columns:\n",
    "    print(col)\n",
    "max_iter = max(cra.get_all_iterations(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results from json Files\n",
    "The results of the simulation are saved in json files.\n",
    "Due to the parallelized nature of the simulation, not all results are in one big json file but rather in multiple batches. We therefore need to combine these batches to obtain a complete set for a given iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to inspect which entries our generated dataset has. Therefore, we normalize the dict, transforming it into a dataframe.\n",
    "Afterwards, we display all columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "1. Determine how the Cargo size changes over the course of the simulation\n",
    "2. Determine if ATG11Receptor actually clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = cra.get_particles_at_iter(output_path, max_iter)\n",
    "# \n",
    "# cargo_at_end = df[df[\"element.cell.interaction.species\"]==\"Cargo\"][\"element.cell.mechanics.mechanics.pos\"]\n",
    "# cargo_at_end = np.array([np.array(elem) for elem in cargo_at_end])\n",
    "# non_cargo_at_end = df[df[\"element.cell.interaction.species\"]!=\"Cargo\"][\"element.cell.mechanics.mechanics.pos\"]\n",
    "# non_cargo_at_end = np.array([np.array(elem) for elem in non_cargo_at_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all scatter snapshots\n",
    "# cra.save_all_scatter_snapshots(output_path, threads=-1)\n",
    "\n",
    "# Also create a movie with ffmpeg\n",
    "# bashcmd = f\"ffmpeg -y -r 30 -f image2 -pattern_type glob -i '{output_path}/scatterplots/*.png' -c:v h264 -pix_fmt yuv420p -strict -2 {output_path}/scatter_movie.mp4\"\n",
    "# os.system(bashcmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "path = Path(\"out/autophagy/\")\n",
    "\n",
    "for exp_dir in os.listdir(path):\n",
    "    if exp_dir[0:4] == \"expl\":\n",
    "        number = exp_dir.split(\"_\")[-1]\n",
    "        subdir = os.listdir(path / exp_dir)[0]\n",
    "        shutil.copyfile(path / exp_dir / subdir / \"snapshots/snapshot_00020000.png\", f\"snapshot_{number}.png\")\n",
    "        shutil.copyfile(path / exp_dir / subdir / \"simulation_settings.json\", f\"simulation_settings_{number}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "def combine_plots(simulation_settings):\n",
    "    number = simulation_settings.split(\".\")[-2].split(\"_\")[-1]\n",
    "    f = open(simulation_settings)\n",
    "    simulation_settings = json.load(f)\n",
    "\n",
    "    potential_strength_r11_r11 = simulation_settings[\"potential_strength_r11_r11\"]\n",
    "    potential_strength_cargo_r11 = simulation_settings[\"potential_strength_cargo_r11\"]\n",
    "    potential_strength_cargo_r11_avidity = simulation_settings[\"potential_strength_cargo_r11_avidity\"]\n",
    "    kb_temperature_r11 = simulation_settings[\"kb_temperature_r11\"]\n",
    "\n",
    "    if potential_strength_cargo_r11>=1.1:\n",
    "        return None\n",
    "\n",
    "    cell_text = []\n",
    "    cell_text.append([\"potential_strength_r11_r11\", potential_strength_r11_r11])\n",
    "    cell_text.append([\"potential_strength_cargo_r11\", potential_strength_cargo_r11])\n",
    "    cell_text.append([\"potential_strength_cargo_r11_avidity\", potential_strength_cargo_r11_avidity])\n",
    "    cell_text.append([\"kb_temperature_r11\", kb_temperature_r11])\n",
    "\n",
    "    im = plt.imread(f\"param_space/snapshot_{number}.png\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.axis('off')\n",
    "    ax.table(cell_text)\n",
    "    ax.set_title(f\"Number {number}\")\n",
    "    ax.imshow(im)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"param_space/combined_{number}.png\")\n",
    "    plt.close(fig)\n",
    "    return None\n",
    "\n",
    "entries = glob.glob(\"param_space/*.json\")\n",
    "_ = list(tqdm.tqdm(mp.Pool().imap(combine_plots, entries), total=len(entries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Result\n",
    "We visualize the results in 3D.\n",
    "Therefore we use `pyvista` which internally uses `vtk` as a backend.\n",
    "Since all of our particles are represented as 3D-spheres, we also display them as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save single snapshots or even use all processes of our device to save snapshots for every iteration.\n",
    "The 2nd approach will take up all resources by default. If you want to limit this, have a look at the [Pool object of the multiprocessing](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all snapshots\n",
    "cra.save_all_snapshots(output_path, threads=12)\n",
    "\n",
    "# Also create a movie with ffmpeg\n",
    "bashcmd = f\"ffmpeg -y -r 30 -f image2 -pattern_type glob -i '{output_path}/snapshots/*.png' -c:v h264 -pix_fmt yuv420p -strict -2 {output_path}/snapshot_movie.mp4\"\n",
    "os.system(bashcmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
