{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Autophagy Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific imports for cellular_raza\n",
    "# The package is named cr_autophagy\n",
    "# We want to reload the package when some of the behind-the scenes python functions change\n",
    "# This is what the importlib statements are for\n",
    "import importlib\n",
    "import cr_autophagy as cra\n",
    "importlib.reload(cra)\n",
    "\n",
    "# Imports of general-purpose python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import pyvista as pv\n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "output_path = cra.get_last_output_path()\n",
    "simulation_settings = cra.get_simulation_settings(output_path)\n",
    "iter_0_particles = cra.get_particles_at_iter(output_path, 0)\n",
    "for col in iter_0_particles.columns:\n",
    "    print(col)\n",
    "max_iter = max(cra.get_all_iterations(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results from json Files\n",
    "The results of the simulation are saved in json files.\n",
    "Due to the parallelized nature of the simulation, not all results are in one big json file but rather in multiple batches. We therefore need to combine these batches to obtain a complete set for a given iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to inspect which entries our generated dataset has. Therefore, we normalize the dict, transforming it into a dataframe.\n",
    "Afterwards, we display all columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "1. Determine how the Cargo size changes over the course of the simulation\n",
    "2. Determine if ATG11Receptor actually clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scatter_snapshot(iteration):\n",
    "    df = cra.get_particles_at_iter(output_path, iteration)\n",
    "\n",
    "    cargo_at_end = df[df[\"element.cell.interaction.species\"]==\"Cargo\"][\"element.cell.mechanics.mechanics.pos\"]\n",
    "    cargo_at_end = np.array([np.array(elem) for elem in cargo_at_end])\n",
    "    non_cargo_at_end = df[df[\"element.cell.interaction.species\"]!=\"Cargo\"][\"element.cell.mechanics.mechanics.pos\"]\n",
    "    non_cargo_at_end = np.array([np.array(elem) for elem in non_cargo_at_end])\n",
    "    cargo_middle = np.average(non_cargo_at_end, axis=0)\n",
    "\n",
    "    def appendSpherical_np(xyz):\n",
    "        ptsnew = np.hstack((xyz, np.zeros(xyz.shape)))\n",
    "        xy = xyz[:,0]**2 + xyz[:,1]**2\n",
    "        ptsnew[:,3] = np.sqrt(xy + xyz[:,2]**2)\n",
    "        ptsnew[:,4] = np.arctan2(np.sqrt(xy), xyz[:,2]) # for elevation angle defined from Z-axis down\n",
    "        #ptsnew[:,4] = np.arctan2(xyz[:,2], np.sqrt(xy)) # for elevation angle defined from XY-plane up\n",
    "        ptsnew[:,5] = np.arctan2(xyz[:,1], xyz[:,0])\n",
    "        return ptsnew\n",
    "\n",
    "    non_cargo_at_end_spherical = appendSpherical_np(non_cargo_at_end - cargo_middle)\n",
    "    r = non_cargo_at_end_spherical[:,3]\n",
    "    r_inv = np.max(r) - r\n",
    "    phi = non_cargo_at_end_spherical[:,4]\n",
    "    theta = non_cargo_at_end_spherical[:,5]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Radial distribution of particles around cargo center\")\n",
    "    ax.scatter(phi, theta, s=r_inv, alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel(\"$\\\\varphi$ [rad]\")\n",
    "    ax.set_ylabel(\"$\\\\theta$ [rad]\")\n",
    "    ax.set_xticks([0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi])\n",
    "    ax.set_xticklabels([\"$0$\", \"$\\\\frac{\\\\pi}{4}$\", \"$\\\\frac{\\\\pi}{2}$\", \"$\\\\frac{3\\\\pi}{4}$\", \"$\\\\pi$\"])\n",
    "    ax.set_yticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\n",
    "    ax.set_yticklabels([\"$-\\\\pi$\", \"$-\\\\frac{\\\\pi}{2}$\", \"$0$\", \"$\\\\frac{\\\\pi}{2}$\", \"$\\\\pi$\"])\n",
    "\n",
    "    ax.set_xlim([-np.pi/12, np.pi*(1+1/12)])\n",
    "    ax.set_ylim([-np.pi*(1+1/6), np.pi*(1+1/6)])\n",
    "\n",
    "    ofolder = output_path / \"scatterplots\"\n",
    "    ofolder.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(ofolder / f\"snapshot_{iteration:08}_scatter.png\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool() as p:\n",
    "    p.map(save_scatter_snapshot, cra.get_all_iterations(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create a movie with ffmpeg\n",
    "bashcmd = f\"ffmpeg -y -r 30 -f image2 -pattern_type glob -i '{output_path}/scatterplots/*.png' -c:v h264 -pix_fmt yuv420p -strict -2 {output_path}/scatter_movie.mp4\"\n",
    "os.system(bashcmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Result\n",
    "We visualize the results in 3D.\n",
    "Therefore we use `pyvista` which internally uses `vtk` as a backend.\n",
    "Since all of our particles are represented as 3D-spheres, we also display them as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spheres(iteration):\n",
    "    # Filter for only particles at the specified iteration\n",
    "    df = cra.get_particles_at_iter(output_path, iteration)\n",
    "    # df = df[df[\"iteration\"]==iteration]\n",
    "\n",
    "    # Create a dataset for pyvista for plotting\n",
    "    pset = pv.PolyData(np.array([np.array(x) for x in df[\"element.cell.mechanics.mechanics.pos\"]]))\n",
    "\n",
    "    # Extend dataset by species and diameter\n",
    "    pset.point_data[\"diameter\"] = 2.0*df[\"element.cell.interaction.cell_radius\"]\n",
    "    pset.point_data[\"species\"] = df[\"element.cell.interaction.species\"]\n",
    "\n",
    "    # Create spheres glyphs from dataset\n",
    "    sphere = pv.Sphere()\n",
    "    spheres = pset.glyph(geom=sphere, scale=\"diameter\", orient=False)\n",
    "\n",
    "    return spheres\n",
    "\n",
    "def save_snapshot(iteration):\n",
    "    ofolder = Path(output_path) / \"snapshots\"\n",
    "    ofolder.mkdir(parents=True, exist_ok=True)\n",
    "    opath = ofolder / \"snapshot_{:08}.png\".format(iteration)\n",
    "    if os.path.isfile(opath):\n",
    "        return\n",
    "    spheres = generate_spheres(iteration)\n",
    "\n",
    "    spheres.plot(\n",
    "        off_screen=True,\n",
    "        screenshot=opath,\n",
    "        scalars=\"species\",\n",
    "        scalar_bar_args={\n",
    "            \"title\":\"Species\",\n",
    "        },\n",
    "        cpos=[\n",
    "            (\n",
    "                -1.5*simulation_settings.domain_size,\n",
    "                -1.5*simulation_settings.domain_size,\n",
    "                -1.5*simulation_settings.domain_size\n",
    "            ),(\n",
    "                25,\n",
    "                25,\n",
    "                25\n",
    "            ),(\n",
    "                0.0,\n",
    "                0.0,\n",
    "                0.0\n",
    "            )\n",
    "        ],\n",
    "        jupyter_backend='none',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save single snapshots or even use all processes of our device to save snapshots for every iteration.\n",
    "The 2nd approach will take up all resources by default. If you want to limit this, have a look at the [Pool object of the multiprocessing](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all snapshots\n",
    "with mp.Pool() as p:\n",
    "    p.map(save_snapshot, cra.get_all_iterations(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create a movie with ffmpeg\n",
    "bashcmd = f\"ffmpeg -y -r 30 -f image2 -pattern_type glob -i '{output_path}/snapshots/*.png' -c:v h264 -pix_fmt yuv420p -strict -2 {output_path}/snapshot_movie.mp4\"\n",
    "os.system(bashcmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
