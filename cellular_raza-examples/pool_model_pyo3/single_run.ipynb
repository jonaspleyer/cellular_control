{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pool-Model Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pool_model_pyo3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Simulation Setings\n",
    "These settings are predefined by our current simulation.\n",
    "They directly control properties of the cells.\n",
    "In this example, we focus on a limited subset of parameters which are relevant for our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_settings = SimulationSettings()\n",
    "print(simulation_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = run_simulation(simulation_settings)\n",
    "# output_path = \"out/pool_model/2023-10-31-20:06:34\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read results from json Files\n",
    "The results of the simulation are saved in json files.\n",
    "Due to the parallelized nature of the simulation, not all results are in one big json file but rather in multiple batches. We therefore need to combine these batches to obtain a complete set for a given iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def combine_batches(run_directory):\n",
    "    # Opens all batches in a given directory and stores\n",
    "    # them in one unified big list\n",
    "    combined_batch = []\n",
    "    for batch_file in os.listdir(run_directory):\n",
    "        f = open(run_directory / batch_file)\n",
    "        b = json.load(f)[\"data\"]\n",
    "        combined_batch.extend(b)\n",
    "    return combined_batch\n",
    "\n",
    "def get_cells_at_iterations(output_path):\n",
    "    # Uses the previously defined funtion [combine_batches]\n",
    "    # to read all stored cells at all iterations and stores\n",
    "    # them in a dictionary.\n",
    "    dir = Path(output_path) / \"cell_storage/json/\"\n",
    "    runs = [(x, dir / x) for x in os.listdir(dir)]\n",
    "    result = []\n",
    "    for (n_run, run_directory) in runs:\n",
    "        result.extend([{\"iteration\":int(n_run)} | c for c in combine_batches(run_directory)])\n",
    "    return result\n",
    "\n",
    "cells_at_iter = get_cells_at_iterations(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to inspect which entries our generated dataset has. Therefore, we normalize the dict, transforming it into a dataframe.\n",
    "Afterwards, we display all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.json_normalize(cells_at_iter)\n",
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Colony\n",
    "We plot the bacterial colony using `matplotlib`. All particles are represented by 2D spheres and so we can display them as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "def save_snapshot(iteration):\n",
    "    # Filter for only particles at the specified iteration\n",
    "    df_filtered = df[df[\"iteration\"]==iteration]\n",
    "\n",
    "    # Get positions as large numpy array\n",
    "    positions = np.array([np.array(x) for x in df_filtered[\"element.cell.mechanics.pos\"]])\n",
    "    s = np.array([np.array(x) for x in df_filtered[\"element.cell.interaction.cell_radius\"]])\n",
    "    c = np.array([np.array(x) for x in df_filtered[\"element.cell.cellular_reactions.intracellular_concentrations\"]])\n",
    "    norm = matplotlib.colors.Normalize(\n",
    "        vmin=c.min(),\n",
    "        vmax=c.max(),\n",
    "        clip=True,\n",
    "    )\n",
    "    mapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=matplotlib.cm.summer)\n",
    "    c = mapper.to_rgba(c)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    for pos, si, ci in zip(positions, s, c):\n",
    "        circle = plt.Circle(pos, radius=si, facecolor=ci, edgecolor='k')\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    x_low = positions[:,0].min()\n",
    "    x_high = positions[:,0].max()\n",
    "    x_middle = (x_low+x_high)/2\n",
    "    y_low = positions[:,1].min()\n",
    "    y_high = positions[:,1].max()\n",
    "    y_middle = (y_low+y_high)/2.0\n",
    "\n",
    "    factor = 1.1\n",
    "    ax.set_xlim([x_middle + factor*(x_low-x_middle), x_middle + factor*(x_high-x_middle)])\n",
    "    ax.set_ylim([y_middle + factor*(y_low-y_middle), y_middle + factor*(y_high-y_middle)])\n",
    "\n",
    "    fig.savefig(Path(output_path) / \"snapshot_{:08}.png\".format(iteration))\n",
    "    plt.close(fig)\n",
    "\n",
    "with mp.Pool() as p:\n",
    "    p.map(save_snapshot, np.unique(df[\"iteration\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
